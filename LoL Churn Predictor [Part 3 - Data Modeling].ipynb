{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoL Churn Predictor [Part 3 - Data Modeling]\n",
    "\n",
    "**David Skarbrevik - 2018**\n",
    "\n",
    "In part 2 we cleaned and analyzed our League of Legends data. Now we want to use that data to build a model that completes some sort of churn-like prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "<br>\n",
    "<hr style=\"background-color: black; padding: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "<ol>\n",
    "    <h3><li><a href=\"#section1\">Planning</a></li></h3>\n",
    "    <br>\n",
    "    <h3><li><a href=\"#section2\">Prepparing the data for modeling</a></li></h3>\n",
    "    <br>\n",
    "    <h3><li><a href=\"#section3\">Modeling the data</a></li></h3>\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "<hr style=\"background-color: black; padding: 1px;\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "## Step 1) Planning\n",
    "\n",
    "### What preprocessing steps maybe necessary before fitting data to a model?\n",
    "\n",
    "**There are four things we may need/want to do before training our models:**\n",
    "\n",
    "**1)** OHE encode categorical and binary features\n",
    "\n",
    "**2) [optional]** normalize values (many columns have large values)\n",
    "\n",
    "**3)** create a \"label\" feature that we will predict on\n",
    "\n",
    "**4)** remove unwanted features from the dataset\n",
    "\n",
    "\n",
    "### What prediction tasks to model?\n",
    "\n",
    "Some possibilities:\n",
    "\n",
    "* Will the summoner get to level 3 or higher within the first month of play?\n",
    "* Did the summoner play more than 1 match?\n",
    "* Did the summoner play at least X matches?\n",
    "\n",
    "\n",
    "\n",
    "### What types of models to try?\n",
    "\n",
    "I will start with logistic regression as it seems most fitting for the prediction tasks above, however I will also try some other common models such as random forests. Finally I'll try a simple neural network model if I have time.\n",
    "\n",
    "### Import needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section2'></a>\n",
    "\n",
    "## Step 2) Prepping the data for modeling\n",
    "\n",
    "This is similar to \"cleaning\" phase in last notebook, but all changes to dataset here are for the purposes of ML not general analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, read cleaned dataframe from file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cleaned_riot_data.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) OHE encoding for categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summoner_id', Counter({92201075: 1, 93650017: 1, 92729877: 1})),\n",
       " ('summoner_name', Counter({'TrEx18': 1, 'iMain N01': 1, 'luexolu99': 1})),\n",
       " ('summoner_level', Counter({5: 3})),\n",
       " ('total_matches', Counter({7: 1, 6: 1, 4: 1})),\n",
       " ('first_match_time',\n",
       "  Counter({'2018-01-16T05:50:54.986000+00:00': 1,\n",
       "           '2018-03-10T06:24:33.477000+00:00': 1,\n",
       "           '2018-03-10T06:56:11.750000+00:00': 1})),\n",
       " ('first_match_duration',\n",
       "  Counter({'0 days 00:14:00.000000000': 1,\n",
       "           '0 days 00:16:41.000000000': 1,\n",
       "           '0 days 00:22:54.000000000': 1})),\n",
       " ('first_match_id', Counter({2695060245: 1, 2736710108: 1, 2736716714: 1})),\n",
       " ('assists', Counter({16.0: 1, 4.0: 1, 10.0: 1})),\n",
       " ('champLevel', Counter({12.0: 1, 11.0: 1, 13.0: 1})),\n",
       " ('combatPlayerScore', Counter({0.0: 3})),\n",
       " ('creepsPerMinDeltas_0-10', Counter({5.1: 1, 3.5: 1, 0.8: 1})),\n",
       " ('creepsPerMinDeltas_10-20', Counter({0.0: 2, 3.6: 1})),\n",
       " ('creepsPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('creepsPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_0-10',\n",
       "  Counter({4.800000000000002: 1, 1.7200000000000002: 1, 0.0: 1})),\n",
       " ('csDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('damageDealtToObjectives', Counter({4624.0: 1, 1885.0: 1, 6838.0: 1})),\n",
       " ('damageDealtToTurrets', Counter({4624.0: 1, 1885.0: 1, 5972.0: 1})),\n",
       " ('damageSelfMitigated', Counter({4268.0: 1, 5206.0: 1, 11147.0: 1})),\n",
       " ('damageTakenDiffPerMinDeltas_0-10',\n",
       "  Counter({-205.3: 1, -200.00000000000003: 1, 0.0: 1})),\n",
       " ('damageTakenDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('damageTakenDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('damageTakenDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('damageTakenPerMinDeltas_0-10', Counter({388.2: 1, 478.0: 1, 564.3: 1})),\n",
       " ('damageTakenPerMinDeltas_10-20', Counter({0.0: 2, 862.0999999999997: 1})),\n",
       " ('damageTakenPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('damageTakenPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('deaths', Counter({0.0: 1, 2.0: 2})),\n",
       " ('doubleKills', Counter({0.0: 2, 3.0: 1})),\n",
       " ('firstBloodAssist', Counter({False: 3})),\n",
       " ('firstBloodKill', Counter({False: 3})),\n",
       " ('firstInhibitorAssist', Counter({True: 2, False: 1})),\n",
       " ('firstInhibitorKill', Counter({False: 3})),\n",
       " ('firstTowerAssist', Counter({False: 3})),\n",
       " ('firstTowerKill', Counter({False: 3})),\n",
       " ('goldEarned', Counter({8012.0: 1, 9014.0: 1, 10869.0: 1})),\n",
       " ('goldPerMinDeltas_0-10', Counter({496.3: 1, 318.3: 1, 353.0: 1})),\n",
       " ('goldPerMinDeltas_10-20', Counter({0.0: 2, 412.7: 1})),\n",
       " ('goldPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('goldPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('goldSpent', Counter({2850.0: 1, 8850.0: 1, 6800.0: 1})),\n",
       " ('id', Counter({4.0: 1, 2.0: 2})),\n",
       " ('inhibitorKills', Counter({0.0: 3})),\n",
       " ('item0', Counter({1054.0: 1, 3142.0: 1, 2003.0: 1})),\n",
       " ('item1', Counter({3044.0: 1, 3147.0: 1, 1055.0: 1})),\n",
       " ('item2', Counter({3067.0: 1, 3111.0: 1, 3133.0: 1})),\n",
       " ('item3', Counter({1001.0: 1, 1043.0: 1, 3071.0: 1})),\n",
       " ('item4', Counter({0.0: 1, 1036.0: 1, 3076.0: 1})),\n",
       " ('item5', Counter({0.0: 1, 1055.0: 1, 3086.0: 1})),\n",
       " ('item6', Counter({3340.0: 3})),\n",
       " ('killingSprees', Counter({1.0: 1, 2.0: 1, 3.0: 1})),\n",
       " ('kills', Counter({13.0: 2, 10.0: 1})),\n",
       " ('lane', Counter({'MIDDLE': 1, 'NONE': 1, 'JUNGLE': 1})),\n",
       " ('largestCriticalStrike', Counter({456.0: 1, 0.0: 1, 499.0: 1})),\n",
       " ('largestKillingSpree', Counter({13.0: 1, 9.0: 1, 5.0: 1})),\n",
       " ('largestMultiKill', Counter({1.0: 2, 2.0: 1})),\n",
       " ('latest_match_time',\n",
       "  Counter({'2018-01-17T06:05:14.227000+00:00': 1,\n",
       "           '2018-03-10T14:58:21.007000+00:00': 1,\n",
       "           '2018-03-21T08:32:17.048000+00:00': 1})),\n",
       " ('longestTimeSpentLiving', Counter({0.0: 1, 654.0: 1, 419.0: 1})),\n",
       " ('magicDamageDealt', Counter({3005.0: 1, 968.0: 1, 1229.0: 1})),\n",
       " ('magicDamageDealtToChampions', Counter({2392.0: 1, 888.0: 1, 288.0: 1})),\n",
       " ('magicalDamageTaken', Counter({1005.0: 1, 3374.0: 1, 2291.0: 1})),\n",
       " ('neutralMinionsKilled', Counter({0.0: 1, 4.0: 1, 16.0: 1})),\n",
       " ('neutralMinionsKilledEnemyJungle', Counter({0.0: 2, 4.0: 1})),\n",
       " ('neutralMinionsKilledTeamJungle', Counter({0.0: 2, 13.0: 1})),\n",
       " ('objectivePlayerScore', Counter({0.0: 3})),\n",
       " ('participantId', Counter({4.0: 1, 2.0: 2})),\n",
       " ('pentaKills', Counter({0.0: 3})),\n",
       " ('perkPrimaryStyle', Counter({8400.0: 1, 8100.0: 2})),\n",
       " ('perkSubStyle', Counter({8200.0: 1, 8000.0: 2})),\n",
       " ('physicalDamageDealt', Counter({48136.0: 1, 46817.0: 1, 67383.0: 1})),\n",
       " ('physicalDamageDealtToChampions',\n",
       "  Counter({11330.0: 1, 12594.0: 1, 10907.0: 1})),\n",
       " ('physicalDamageTaken', Counter({7246.0: 1, 7109.0: 1, 14573.0: 1})),\n",
       " ('playerScore0', Counter({0.0: 3})),\n",
       " ('playerScore1', Counter({0.0: 3})),\n",
       " ('playerScore2', Counter({0.0: 3})),\n",
       " ('playerScore3', Counter({0.0: 3})),\n",
       " ('playerScore4', Counter({0.0: 3})),\n",
       " ('playerScore5', Counter({0.0: 3})),\n",
       " ('playerScore6', Counter({0.0: 3})),\n",
       " ('playerScore7', Counter({0.0: 3})),\n",
       " ('playerScore8', Counter({0.0: 3})),\n",
       " ('playerScore9', Counter({0.0: 3})),\n",
       " ('quadraKills', Counter({0.0: 3})),\n",
       " ('role', Counter({'SOLO': 1, 'DUO_SUPPORT': 1, 'NONE': 1})),\n",
       " ('sightWardsBoughtInGame', Counter({0.0: 3})),\n",
       " ('timeCCingOthers', Counter({18.0: 1, 59.0: 1, 36.0: 1})),\n",
       " ('totalDamageDealt', Counter({51142.0: 1, 52490.0: 1, 70890.0: 1})),\n",
       " ('totalDamageDealtToChampions',\n",
       "  Counter({13723.0: 1, 13817.0: 1, 11789.0: 1})),\n",
       " ('totalDamageTaken', Counter({8252.0: 1, 11503.0: 1, 16942.0: 1})),\n",
       " ('totalHeal', Counter({1128.0: 1, 3662.0: 1, 8791.0: 1})),\n",
       " ('totalMinionsKilled', Counter({63.0: 1, 58.0: 1, 50.0: 1})),\n",
       " ('totalPlayerScore', Counter({0.0: 3})),\n",
       " ('totalScoreRank', Counter({0.0: 3})),\n",
       " ('totalTimeCrowdControlDealt', Counter({274.0: 1, 123.0: 1, 145.0: 1})),\n",
       " ('totalUnitsHealed', Counter({1.0: 3})),\n",
       " ('tripleKills', Counter({0.0: 3})),\n",
       " ('trueDamageDealt', Counter({0.0: 1, 4704.0: 1, 2277.0: 1})),\n",
       " ('trueDamageDealtToChampions', Counter({0.0: 1, 334.0: 1, 593.0: 1})),\n",
       " ('trueDamageTaken', Counter({0.0: 1, 1019.0: 1, 77.0: 1})),\n",
       " ('turretKills', Counter({2.0: 2, 0.0: 1})),\n",
       " ('unrealKills', Counter({0.0: 3})),\n",
       " ('visionScore', Counter({0.0: 2, 3.0: 1})),\n",
       " ('visionWardsBoughtInGame', Counter({0.0: 3})),\n",
       " ('wardsKilled', Counter({0.0: 3})),\n",
       " ('wardsPlaced', Counter({0.0: 2, 3.0: 1})),\n",
       " ('win', Counter({True: 3})),\n",
       " ('xpDiffPerMinDeltas_0-10',\n",
       "  Counter({371.20000000000016: 1, 84.65999999999998: 1, 0.0: 1})),\n",
       " ('xpDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('xpDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('xpDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('xpPerMinDeltas_0-10', Counter({583.9000000000002: 1, 363.9: 1, 331.8: 1})),\n",
       " ('xpPerMinDeltas_10-20', Counter({0.0: 2, 464.2: 1})),\n",
       " ('xpPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('xpPerMinDeltas_30-end', Counter({0.0: 3}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(feature, Counter(df[feature].head(n=3))) for feature in list(df)] # which features are categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like just the 'lane' and 'role' features are categorical so let's OHE those. \n",
    "\n",
    "Note also, there are a couple True/False columns. Python and python libraries usually treats them as 1/0 already but we'll explicitly change them just in case it causes trouble later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dummy_lane = pd.get_dummies(df['lane'])\n",
    "dummy_role = pd.get_dummies(df['role'])\n",
    "\n",
    "dummy_role.columns.values[3] = \"NO_ROLE\"\n",
    "dummy_lane.columns.values[3] = \"NO_LANE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>NO_LANE</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOTTOM  JUNGLE  MIDDLE  NO_LANE  TOP\n",
       "0       0       0       1        0    0\n",
       "1       0       0       0        1    0\n",
       "2       0       1       0        0    0\n",
       "3       0       0       0        0    1\n",
       "4       0       1       0        0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lane.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUO</th>\n",
       "      <th>DUO_CARRY</th>\n",
       "      <th>DUO_SUPPORT</th>\n",
       "      <th>NO_ROLE</th>\n",
       "      <th>SOLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DUO  DUO_CARRY  DUO_SUPPORT  NO_ROLE  SOLO\n",
       "0    0          0            0        0     1\n",
       "1    0          0            1        0     0\n",
       "2    0          0            0        1     0\n",
       "3    0          0            1        0     0\n",
       "4    0          0            0        1     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_role.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['lane', 'role'], axis=1)\n",
    "df = df.join([dummy_role,dummy_lane])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boolean_features = ['firstBloodAssist', 'firstBloodKill', 'firstInhibitorAssist', \n",
    "                    'firstInhibitorKill', 'firstTowerAssist', 'firstTowerKill', 'win']\n",
    "\n",
    "df[boolean_features] = df[boolean_features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just make sure all our features are numeric now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summoner_id</th>\n",
       "      <th>summoner_name</th>\n",
       "      <th>summoner_level</th>\n",
       "      <th>total_matches</th>\n",
       "      <th>first_match_time</th>\n",
       "      <th>first_match_duration</th>\n",
       "      <th>first_match_id</th>\n",
       "      <th>assists</th>\n",
       "      <th>champLevel</th>\n",
       "      <th>combatPlayerScore</th>\n",
       "      <th>...</th>\n",
       "      <th>DUO</th>\n",
       "      <th>DUO_CARRY</th>\n",
       "      <th>DUO_SUPPORT</th>\n",
       "      <th>NO_ROLE</th>\n",
       "      <th>SOLO</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>NO_LANE</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92201075</td>\n",
       "      <td>TrEx18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-01-16T05:50:54.986000+00:00</td>\n",
       "      <td>0 days 00:14:00.000000000</td>\n",
       "      <td>2695060245</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93650017</td>\n",
       "      <td>iMain N01</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-03-10T06:24:33.477000+00:00</td>\n",
       "      <td>0 days 00:16:41.000000000</td>\n",
       "      <td>2736710108</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92729877</td>\n",
       "      <td>luexolu99</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-10T06:56:11.750000+00:00</td>\n",
       "      <td>0 days 00:22:54.000000000</td>\n",
       "      <td>2736716714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93839689</td>\n",
       "      <td>Md95359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-09T13:05:59.377000+00:00</td>\n",
       "      <td>0 days 00:28:54.000000000</td>\n",
       "      <td>2736217337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93599676</td>\n",
       "      <td>lwvvs</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-03-09T11:42:58.309000+00:00</td>\n",
       "      <td>0 days 00:30:05.000000000</td>\n",
       "      <td>2736195812</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   summoner_id summoner_name  summoner_level  total_matches  \\\n",
       "0     92201075        TrEx18               5              7   \n",
       "1     93650017     iMain N01               5              6   \n",
       "2     92729877     luexolu99               5              4   \n",
       "3     93839689       Md95359               1              1   \n",
       "4     93599676         lwvvs               5              6   \n",
       "\n",
       "                   first_match_time       first_match_duration  \\\n",
       "0  2018-01-16T05:50:54.986000+00:00  0 days 00:14:00.000000000   \n",
       "1  2018-03-10T06:24:33.477000+00:00  0 days 00:16:41.000000000   \n",
       "2  2018-03-10T06:56:11.750000+00:00  0 days 00:22:54.000000000   \n",
       "3  2018-03-09T13:05:59.377000+00:00  0 days 00:28:54.000000000   \n",
       "4  2018-03-09T11:42:58.309000+00:00  0 days 00:30:05.000000000   \n",
       "\n",
       "   first_match_id  assists  champLevel  combatPlayerScore ...   DUO  \\\n",
       "0      2695060245     16.0        12.0                0.0 ...     0   \n",
       "1      2736710108      4.0        11.0                0.0 ...     0   \n",
       "2      2736716714     10.0        13.0                0.0 ...     0   \n",
       "3      2736217337      0.0         1.0                0.0 ...     0   \n",
       "4      2736195812      7.0        17.0                0.0 ...     0   \n",
       "\n",
       "   DUO_CARRY  DUO_SUPPORT  NO_ROLE  SOLO  BOTTOM  JUNGLE  MIDDLE  NO_LANE  TOP  \n",
       "0          0            0        0     1       0       0       1        0    0  \n",
       "1          0            1        0     0       0       0       0        1    0  \n",
       "2          0            0        1     0       0       1       0        0    0  \n",
       "3          0            1        0     0       0       0       0        0    1  \n",
       "4          0            0        1     0       0       1       0        0    0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Normalize feature values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# skipping this step for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Create a prediction task label feature**\n",
    "\n",
    "We are trying to predict, from a player's first match stats, if they will play enough to reach summoner level 3 or greater. \n",
    "\n",
    "Let's see what the summoner level breakdown for players is in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 453, 1: 192, 4: 377, 3: 279, 2: 194})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_counts = Counter(df['summoner_level'])\n",
    "level_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a good amount of each summoner level 1-5. Let's make prediction labels where `level < 3` gets `0` and `level >= 3` gets `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "level_data = df['summoner_level'].tolist()\n",
    "labels = []\n",
    "\n",
    "for value in level_data:\n",
    "    if value < 3:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1109, 0: 386})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may not be as many players under level 3 as we'd like, there are still over 300 examples in this group, so this may be a reasonable dataset to prototype the viability of our prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Removing unwanted features**\n",
    "\n",
    "Some features like \"summoner_name\" aren't relevant to training our model and others like \"total_matches\" and \"summoner_level\" give the model information we don't want it to have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summoner_id',\n",
       " 'summoner_name',\n",
       " 'summoner_level',\n",
       " 'total_matches',\n",
       " 'first_match_time',\n",
       " 'first_match_duration',\n",
       " 'first_match_id',\n",
       " 'assists',\n",
       " 'champLevel',\n",
       " 'combatPlayerScore',\n",
       " 'creepsPerMinDeltas_0-10',\n",
       " 'creepsPerMinDeltas_10-20',\n",
       " 'creepsPerMinDeltas_20-30',\n",
       " 'creepsPerMinDeltas_30-end',\n",
       " 'csDiffPerMinDeltas_0-10',\n",
       " 'csDiffPerMinDeltas_10-20',\n",
       " 'csDiffPerMinDeltas_20-30',\n",
       " 'csDiffPerMinDeltas_30-end',\n",
       " 'damageDealtToObjectives',\n",
       " 'damageDealtToTurrets',\n",
       " 'damageSelfMitigated',\n",
       " 'damageTakenDiffPerMinDeltas_0-10',\n",
       " 'damageTakenDiffPerMinDeltas_10-20',\n",
       " 'damageTakenDiffPerMinDeltas_20-30',\n",
       " 'damageTakenDiffPerMinDeltas_30-end',\n",
       " 'damageTakenPerMinDeltas_0-10',\n",
       " 'damageTakenPerMinDeltas_10-20',\n",
       " 'damageTakenPerMinDeltas_20-30',\n",
       " 'damageTakenPerMinDeltas_30-end',\n",
       " 'deaths',\n",
       " 'doubleKills',\n",
       " 'firstBloodAssist',\n",
       " 'firstBloodKill',\n",
       " 'firstInhibitorAssist',\n",
       " 'firstInhibitorKill',\n",
       " 'firstTowerAssist',\n",
       " 'firstTowerKill',\n",
       " 'goldEarned',\n",
       " 'goldPerMinDeltas_0-10',\n",
       " 'goldPerMinDeltas_10-20',\n",
       " 'goldPerMinDeltas_20-30',\n",
       " 'goldPerMinDeltas_30-end',\n",
       " 'goldSpent',\n",
       " 'id',\n",
       " 'inhibitorKills',\n",
       " 'item0',\n",
       " 'item1',\n",
       " 'item2',\n",
       " 'item3',\n",
       " 'item4',\n",
       " 'item5',\n",
       " 'item6',\n",
       " 'killingSprees',\n",
       " 'kills',\n",
       " 'largestCriticalStrike',\n",
       " 'largestKillingSpree',\n",
       " 'largestMultiKill',\n",
       " 'latest_match_time',\n",
       " 'longestTimeSpentLiving',\n",
       " 'magicDamageDealt',\n",
       " 'magicDamageDealtToChampions',\n",
       " 'magicalDamageTaken',\n",
       " 'neutralMinionsKilled',\n",
       " 'neutralMinionsKilledEnemyJungle',\n",
       " 'neutralMinionsKilledTeamJungle',\n",
       " 'objectivePlayerScore',\n",
       " 'participantId',\n",
       " 'pentaKills',\n",
       " 'perkPrimaryStyle',\n",
       " 'perkSubStyle',\n",
       " 'physicalDamageDealt',\n",
       " 'physicalDamageDealtToChampions',\n",
       " 'physicalDamageTaken',\n",
       " 'playerScore0',\n",
       " 'playerScore1',\n",
       " 'playerScore2',\n",
       " 'playerScore3',\n",
       " 'playerScore4',\n",
       " 'playerScore5',\n",
       " 'playerScore6',\n",
       " 'playerScore7',\n",
       " 'playerScore8',\n",
       " 'playerScore9',\n",
       " 'quadraKills',\n",
       " 'sightWardsBoughtInGame',\n",
       " 'timeCCingOthers',\n",
       " 'totalDamageDealt',\n",
       " 'totalDamageDealtToChampions',\n",
       " 'totalDamageTaken',\n",
       " 'totalHeal',\n",
       " 'totalMinionsKilled',\n",
       " 'totalPlayerScore',\n",
       " 'totalScoreRank',\n",
       " 'totalTimeCrowdControlDealt',\n",
       " 'totalUnitsHealed',\n",
       " 'tripleKills',\n",
       " 'trueDamageDealt',\n",
       " 'trueDamageDealtToChampions',\n",
       " 'trueDamageTaken',\n",
       " 'turretKills',\n",
       " 'unrealKills',\n",
       " 'visionScore',\n",
       " 'visionWardsBoughtInGame',\n",
       " 'wardsKilled',\n",
       " 'wardsPlaced',\n",
       " 'win',\n",
       " 'xpDiffPerMinDeltas_0-10',\n",
       " 'xpDiffPerMinDeltas_10-20',\n",
       " 'xpDiffPerMinDeltas_20-30',\n",
       " 'xpDiffPerMinDeltas_30-end',\n",
       " 'xpPerMinDeltas_0-10',\n",
       " 'xpPerMinDeltas_10-20',\n",
       " 'xpPerMinDeltas_20-30',\n",
       " 'xpPerMinDeltas_30-end',\n",
       " 'DUO',\n",
       " 'DUO_CARRY',\n",
       " 'DUO_SUPPORT',\n",
       " 'NO_ROLE',\n",
       " 'SOLO',\n",
       " 'BOTTOM',\n",
       " 'JUNGLE',\n",
       " 'MIDDLE',\n",
       " 'NO_LANE',\n",
       " 'TOP']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in full dataset: 124\n",
      "Number of features in model training dataset: 115\n"
     ]
    }
   ],
   "source": [
    "extra_features = ['summoner_id', 'summoner_level', 'summoner_name', 'id', 'first_match_time',\n",
    "                  'first_match_id', 'first_match_duration', 'latest_match_time', 'total_matches']\n",
    "\n",
    "num_full_features = df.shape[1]\n",
    "\n",
    "df = df.drop(extra_features, axis=1)\n",
    "\n",
    "num_training_features = df.shape[1]\n",
    "\n",
    "print(\"Number of features in full dataset: {}\".format(num_full_features))\n",
    "print(\"Number of features in model training dataset: {}\".format(num_training_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly let's save the ML ready dataset and prediction labels for future use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/riot_cleaned_ml_data.csv\", index=False) # dataset\n",
    "pd.DataFrame(labels).to_csv(\"./data/ml_data_labels.csv\", index=False) # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! We're finally ready to fit our data to some models!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section3'></a>\n",
    "\n",
    "## Step 3) Modeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML ready data\n",
    "df = pd.read_csv(\"./data/riot_cleaned_ml_data.csv\", encoding=\"ISO-8859-1\")\n",
    "labels = pd.read_csv(\"./data/ml_data_labels.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomize and split data into train/test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define our training data and label data\n",
    "X = np.array(df)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 1196\n",
      "Training labels: 1196\n",
      "Test examples: 299\n",
      "Test labels: 299\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.80, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Training examples: {}\".format(X_train.shape[0]))\n",
    "print(\"Training labels: {}\".format(Y_train.shape[0]))\n",
    "print(\"Test examples: {}\".format(X_test.shape[0]))\n",
    "print(\"Test labels: {}\".format(Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model on test data: 74.25%\n",
      "F1-score for logistic regression model on test data: 0.84\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = log_model.score(X_test, Y_test)\n",
    "preds = log_model.predict(X_test)\n",
    "log_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of logistic regression model on test data: {:.2f}%\".format(logistic_accuracy*100))\n",
    "print(\"F1-score for logistic regression model on test data: {:.2f}\".format(log_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not bad at all!**\n",
    "\n",
    "There are a lot of qualifiers we should point out about this result before we jump for joy, but 74% accuracy on this relatively small dataset with just a vanilla, out of the box, logistic regression model is very encouraging.\n",
    "\n",
    "Next, let's try some other out of the box models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 64.21%\n",
      "F1-score for ada boosted model on test data: 0.76\n"
     ]
    }
   ],
   "source": [
    "tree_accuracy = tree_model.score(X_test, Y_test)\n",
    "preds = tree_model.predict(X_test)\n",
    "tree_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(tree_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(tree_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 70.90%\n",
      "F1-score for ada boosted model on test data: 0.82\n"
     ]
    }
   ],
   "source": [
    "forest_accuracy = forest_model.score(X_test, Y_test)\n",
    "preds = forest_model.predict(X_test)\n",
    "forest_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(forest_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(forest_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model = GradientBoostingClassifier()\n",
    "gradient_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 73.91%\n",
      "F1-score for ada boosted model on test data: 0.84\n"
     ]
    }
   ],
   "source": [
    "gradient_accuracy = gradient_model.score(X_test, Y_test)\n",
    "preds = gradient_model.predict(X_test)\n",
    "gradient_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(gradient_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(gradient_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model = AdaBoostClassifier()\n",
    "ada_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 70.90%\n",
      "F1-score for ada boosted model on test data: 0.81\n"
     ]
    }
   ],
   "source": [
    "ada_accuracy = ada_model.score(X_test, Y_test)\n",
    "preds = ada_model.predict(X_test)\n",
    "ada_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(ada_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(ada_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary of Basic Models</h3>\n",
    "\n",
    "<br>\n",
    "\n",
    "<table align=\"left\" style=\"width:30%\">\n",
    "    <tr>\n",
    "        <th>Model Type</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>F1-Score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Logistic Regression</td>\n",
    "        <td>74.25%</td>\n",
    "        <td>0.84</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Decision Tree</td>\n",
    "        <td>62.21%</td>\n",
    "        <td>0.74</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Random Forest</td>\n",
    "        <td>70.90%</td>\n",
    "        <td>0.82</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Gradient Boosting</td>\n",
    "        <td>73.91%</td>\n",
    "        <td>0.84</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ada Boosting</td>\n",
    "        <td>70.90%</td>\n",
    "        <td>0.81</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"padding-left:350px;\"> We achieved good results with logistic regression and random forests without any hyperparameter tuning. Because logistic regression worked so well, I'm curious how a small feed-forward neural network will fare on this dataset. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transpose train/test set to prepare for neural network\n",
    "X_train_network = X_train.T\n",
    "X_test_network = X_test.T\n",
    "Y_train_network = Y_train.reshape(1, Y_train.shape[0])\n",
    "Y_test_network = Y_test.reshape(1, Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (115, 1196)\n",
      "Training labels shape: (1, 1196)\n",
      "\n",
      "\n",
      "Test set shape: (115, 299)\n",
      "Test labels shape: (1, 299)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape: {}\".format(X_train_network.shape))\n",
    "print(\"Training labels shape: {}\".format(Y_train_network.shape))\n",
    "print(\"\\n\")\n",
    "print(\"Test set shape: {}\".format(X_test_network.shape))\n",
    "print(\"Test labels shape: {}\".format(Y_test_network.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network(X_train_network, Y_train_network, X_test_network, Y_test_network, \n",
    "                   num_layers, nodes_in_layer, num_epochs, learning_rate):\n",
    "\n",
    "    # to allow re-running of the network\n",
    "    ops.reset_default_graph()                         \n",
    "    \n",
    "    # make sure all layers are assigned nodes\n",
    "    assert num_layers == len(nodes_in_layer)\n",
    "\n",
    "    \n",
    "    costs = []\n",
    "    parameters = {}\n",
    "    activations = {}\n",
    "     \n",
    "        \n",
    "    # step 1) placeholders for data\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[X_train_network.shape[0], None], name=\"X_data\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[Y_train_network.shape[0], None], name=\"Y_data\")\n",
    "\n",
    "    \n",
    "    # step 2) initialize network parameters\n",
    "\n",
    "    parameters[\"W1\"] = tf.get_variable(\"W1\", [nodes_in_layer[0],X_train_network.shape[0]], initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "    parameters[\"b1\"] = tf.get_variable(\"b1\", [nodes_in_layer[0],1], initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "    print(\"W1 shape = {}\".format(parameters[\"W1\"].get_shape()))\n",
    "    print(\"b1 shape = {}\".format(parameters[\"b1\"].get_shape()))\n",
    "\n",
    "    for i in range(1,num_layers):\n",
    "        parameters[\"W{}\".format(i+1)] = tf.get_variable(\"W{}\".format(i+1), [nodes_in_layer[i],nodes_in_layer[i-1]], \n",
    "                                                        initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "        \n",
    "        print(\"W{0} shape = {1}\".format((i+1),parameters[\"W{}\".format(i+1)].get_shape()))\n",
    "        parameters[\"b{}\".format(i+1)] = tf.get_variable(\"b{}\".format(i+1), [nodes_in_layer[i], 1], \n",
    "                                                        initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "        print(\"b{0} shape = {1}\".format((i+1),parameters[\"b{}\".format(i+1)].get_shape()))\n",
    "\n",
    "        \n",
    "    # step 3) forward propagation\n",
    "    \n",
    "    activations[\"Z1\"] = tf.add(tf.matmul(parameters[\"W1\"], X), parameters[\"b1\"])\n",
    "    activations[\"A1\"] = tf.nn.relu(activations[\"Z1\"])\n",
    "    print(\"Z1 shape = {}\".format(activations[\"Z1\"].get_shape()))\n",
    "    print(\"A1 shape = {}\".format(activations[\"A1\"].get_shape()))\n",
    "    \n",
    "    for i in range(1,num_layers):\n",
    "        activations[\"Z{}\".format(i+1)] = tf.add(tf.matmul(parameters[\"W{}\".format(i+1)],\n",
    "                                                          activations[\"A{}\".format(i)]), parameters[\"b{}\".format(i+1)])\n",
    "        \n",
    "        print(\"Z{0} shape = {1}\".format((i+1),activations[\"Z{}\".format(i+1)].get_shape()))\n",
    "        \n",
    "        activations[\"A{}\".format(i+1)] = tf.nn.relu(activations[\"Z{}\".format(i+1)])  \n",
    "        \n",
    "        print(\"A{0} shape = {1}\".format((i+1),activations[\"A{}\".format(i+1)].get_shape()))\n",
    "     \n",
    "    # step 4) compute cost\n",
    "    logits = tf.transpose(activations[\"Z{}\".format(num_layers)])\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    \n",
    "    # step 5) backpropagation\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    \n",
    "    # step 6) initialize and run Session\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "    \n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train_network, Y: Y_train_network})\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if epoch % 1 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if epoch % 1 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        trained_parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(activations[\"Z{}\".format(num_layers)]), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train_network, Y: Y_train_network}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test_network, Y: Y_test_network}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to use our neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (25, 115)\n",
      "b1 shape = (25, 1)\n",
      "W2 shape = (12, 25)\n",
      "b2 shape = (12, 1)\n",
      "W3 shape = (1, 12)\n",
      "b3 shape = (1, 1)\n",
      "Z1 shape = (25, ?)\n",
      "A1 shape = (25, ?)\n",
      "Z2 shape = (12, ?)\n",
      "A2 shape = (12, ?)\n",
      "Z3 shape = (1, ?)\n",
      "A3 shape = (1, ?)\n",
      "Cost after epoch 0: 592.924805\n",
      "Cost after epoch 1: 29188232.000000\n",
      "Cost after epoch 2: 121229085471932416.000000\n",
      "Cost after epoch 3: 164177.718750\n",
      "Cost after epoch 4: 6.723952\n",
      "Cost after epoch 5: 1.008456\n",
      "Cost after epoch 6: 0.583913\n",
      "Cost after epoch 7: 0.578230\n",
      "Cost after epoch 8: 0.578004\n",
      "Cost after epoch 9: 0.577786\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c24350ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'W1': <tf.Variable 'W1:0' shape=(25, 115) dtype=float32_ref>,\n",
       " 'W2': <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>,\n",
       " 'W3': <tf.Variable 'W3:0' shape=(1, 12) dtype=float32_ref>,\n",
       " 'b1': <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>,\n",
       " 'b2': <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>,\n",
       " 'b3': <tf.Variable 'b3:0' shape=(1, 1) dtype=float32_ref>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed for reproducibility\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "# choose your parameters\n",
    "num_layers = 3\n",
    "nodes_in_layer = [25,12,1]\n",
    "num_epochs= 10\n",
    "learning_rate = 0.05\n",
    "\n",
    "# train and test the network\n",
    "neural_network(X_train_network, Y_train_network, X_test_network, Y_test_network, \n",
    "               num_layers, nodes_in_layer, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[n_x, None], name=\"X_data\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y, None], name=\"Y_data\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)                   \n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [25,115], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        \n",
    "    A1 = tf.nn.relu(Z1)                                   \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       \n",
    "    A2 = tf.nn.relu(Z2)                                    \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       \n",
    "\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "\n",
    "    np.random.seed(seed)            \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "\n",
    "        mini_batch_X = shuffled_X[:, (num_complete_minibatches)*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:, (num_complete_minibatches)*mini_batch_size:]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = model(X_train_network, Y_train_network, X_test_network, Y_test_network, num_epochs=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in essentially no time, this simple neural network found parameters that fit the training set perfectly AND still performed perfectly on the test set. I'll need to investigate whether this is result is real or if I made a mistake setting up this network..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "\n",
    "## End of Part 3\n",
    "\n",
    "## That's it!\n",
    "\n",
    "We've seen that it is possible to predict (with great accuracy) whether a new League of Legends player will ge through their tutorial matches (reach summoner level 3) or not, based only on the gameplay data of that player's first match!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
