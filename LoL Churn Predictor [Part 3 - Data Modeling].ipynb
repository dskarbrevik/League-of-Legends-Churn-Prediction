{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoL Churn Predictor [Part 3 - Data Modeling]\n",
    "\n",
    "**David Skarbrevik - 2018**\n",
    "\n",
    "In part 2 we cleaned and analyzed our League of Legends data. Now we want to use that data to build a model that completes some sort of churn-like prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"toc\"></a>\n",
    "\n",
    "<br>\n",
    "<hr style=\"background-color: black; padding: 1px;\">\n",
    "<br>\n",
    "\n",
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<br>\n",
    "\n",
    "<ol>\n",
    "    <h3><li><a href=\"#section1\">Planning</a></li></h3>\n",
    "    <br>\n",
    "    <h3><li><a href=\"#section2\">Prepparing the data for modeling</a></li></h3>\n",
    "    <br>\n",
    "    <h3><li><a href=\"#section3\">Modeling the data</a></li></h3>\n",
    "</ol>\n",
    "\n",
    "<br>\n",
    "<hr style=\"background-color: black; padding: 1px;\">\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "\n",
    "## Step 1) Planning\n",
    "\n",
    "### What preprocessing steps maybe necessary before fitting data to a model?\n",
    "\n",
    "**There are four things we may need/want to do before training our models:**\n",
    "\n",
    "**1)** OHE encode categorical and binary features\n",
    "\n",
    "**2) [optional]** normalize values (many columns have large values)\n",
    "\n",
    "**3)** create a \"label\" feature that we will predict on\n",
    "\n",
    "**4)** remove unwanted features from the dataset\n",
    "\n",
    "\n",
    "### What prediction tasks to model?\n",
    "\n",
    "Some possibilities:\n",
    "\n",
    "* Will the summoner get to level 3 or higher within the first month of play?\n",
    "* Did the summoner play more than 1 match?\n",
    "* Did the summoner play at least X matches?\n",
    "\n",
    "\n",
    "\n",
    "### What types of models to try?\n",
    "\n",
    "I will start with logistic regression as it seems most fitting for the prediction tasks above, however I will also try some other common models such as random forests. Finally I'll try a simple neural network model if I have time.\n",
    "\n",
    "### Import needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section2'></a>\n",
    "\n",
    "## Step 2) Prepping the data for modeling\n",
    "\n",
    "This is similar to \"cleaning\" phase in last notebook, but all changes to dataset here are for the purposes of ML not general analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First, read cleaned dataframe from file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cleaned_riot_data.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) OHE encoding for categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('summoner_id', Counter({92201075: 1, 93650017: 1, 92729877: 1})),\n",
       " ('summoner_name', Counter({'TrEx18': 1, 'iMain N01': 1, 'luexolu99': 1})),\n",
       " ('summoner_level', Counter({5: 3})),\n",
       " ('total_matches', Counter({7: 1, 6: 1, 4: 1})),\n",
       " ('first_match_time',\n",
       "  Counter({'2018-01-16T05:50:54.986000+00:00': 1,\n",
       "           '2018-03-10T06:24:33.477000+00:00': 1,\n",
       "           '2018-03-10T06:56:11.750000+00:00': 1})),\n",
       " ('first_match_duration',\n",
       "  Counter({'0 days 00:14:00.000000000': 1,\n",
       "           '0 days 00:16:41.000000000': 1,\n",
       "           '0 days 00:22:54.000000000': 1})),\n",
       " ('first_match_id', Counter({2695060245: 1, 2736710108: 1, 2736716714: 1})),\n",
       " ('assists', Counter({16.0: 1, 4.0: 1, 10.0: 1})),\n",
       " ('champLevel', Counter({12.0: 1, 11.0: 1, 13.0: 1})),\n",
       " ('combatPlayerScore', Counter({0.0: 3})),\n",
       " ('creepsPerMinDeltas_0-10', Counter({5.1: 1, 3.5: 1, 0.8: 1})),\n",
       " ('creepsPerMinDeltas_10-20', Counter({0.0: 2, 3.6: 1})),\n",
       " ('creepsPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('creepsPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_0-10',\n",
       "  Counter({4.800000000000002: 1, 1.7200000000000002: 1, 0.0: 1})),\n",
       " ('csDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('csDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('damageDealtToObjectives', Counter({4624.0: 1, 1885.0: 1, 6838.0: 1})),\n",
       " ('damageDealtToTurrets', Counter({4624.0: 1, 1885.0: 1, 5972.0: 1})),\n",
       " ('damageSelfMitigated', Counter({4268.0: 1, 5206.0: 1, 11147.0: 1})),\n",
       " ('damageTakenDiffPerMinDeltas_0-10',\n",
       "  Counter({-205.3: 1, -200.00000000000003: 1, 0.0: 1})),\n",
       " ('damageTakenDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('damageTakenDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('damageTakenDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('damageTakenPerMinDeltas_0-10', Counter({388.2: 1, 478.0: 1, 564.3: 1})),\n",
       " ('damageTakenPerMinDeltas_10-20', Counter({0.0: 2, 862.0999999999997: 1})),\n",
       " ('damageTakenPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('damageTakenPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('deaths', Counter({0.0: 1, 2.0: 2})),\n",
       " ('doubleKills', Counter({0.0: 2, 3.0: 1})),\n",
       " ('firstBloodAssist', Counter({False: 3})),\n",
       " ('firstBloodKill', Counter({False: 3})),\n",
       " ('firstInhibitorAssist', Counter({True: 2, False: 1})),\n",
       " ('firstInhibitorKill', Counter({False: 3})),\n",
       " ('firstTowerAssist', Counter({False: 3})),\n",
       " ('firstTowerKill', Counter({False: 3})),\n",
       " ('goldEarned', Counter({8012.0: 1, 9014.0: 1, 10869.0: 1})),\n",
       " ('goldPerMinDeltas_0-10', Counter({496.3: 1, 318.3: 1, 353.0: 1})),\n",
       " ('goldPerMinDeltas_10-20', Counter({0.0: 2, 412.7: 1})),\n",
       " ('goldPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('goldPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('goldSpent', Counter({2850.0: 1, 8850.0: 1, 6800.0: 1})),\n",
       " ('id', Counter({4.0: 1, 2.0: 2})),\n",
       " ('inhibitorKills', Counter({0.0: 3})),\n",
       " ('item0', Counter({1054.0: 1, 3142.0: 1, 2003.0: 1})),\n",
       " ('item1', Counter({3044.0: 1, 3147.0: 1, 1055.0: 1})),\n",
       " ('item2', Counter({3067.0: 1, 3111.0: 1, 3133.0: 1})),\n",
       " ('item3', Counter({1001.0: 1, 1043.0: 1, 3071.0: 1})),\n",
       " ('item4', Counter({0.0: 1, 1036.0: 1, 3076.0: 1})),\n",
       " ('item5', Counter({0.0: 1, 1055.0: 1, 3086.0: 1})),\n",
       " ('item6', Counter({3340.0: 3})),\n",
       " ('killingSprees', Counter({1.0: 1, 2.0: 1, 3.0: 1})),\n",
       " ('kills', Counter({13.0: 2, 10.0: 1})),\n",
       " ('lane', Counter({'MIDDLE': 1, 'NONE': 1, 'JUNGLE': 1})),\n",
       " ('largestCriticalStrike', Counter({456.0: 1, 0.0: 1, 499.0: 1})),\n",
       " ('largestKillingSpree', Counter({13.0: 1, 9.0: 1, 5.0: 1})),\n",
       " ('largestMultiKill', Counter({1.0: 2, 2.0: 1})),\n",
       " ('latest_match_time',\n",
       "  Counter({'2018-01-17T06:05:14.227000+00:00': 1,\n",
       "           '2018-03-10T14:58:21.007000+00:00': 1,\n",
       "           '2018-03-21T08:32:17.048000+00:00': 1})),\n",
       " ('longestTimeSpentLiving', Counter({0.0: 1, 654.0: 1, 419.0: 1})),\n",
       " ('magicDamageDealt', Counter({3005.0: 1, 968.0: 1, 1229.0: 1})),\n",
       " ('magicDamageDealtToChampions', Counter({2392.0: 1, 888.0: 1, 288.0: 1})),\n",
       " ('magicalDamageTaken', Counter({1005.0: 1, 3374.0: 1, 2291.0: 1})),\n",
       " ('neutralMinionsKilled', Counter({0.0: 1, 4.0: 1, 16.0: 1})),\n",
       " ('neutralMinionsKilledEnemyJungle', Counter({0.0: 2, 4.0: 1})),\n",
       " ('neutralMinionsKilledTeamJungle', Counter({0.0: 2, 13.0: 1})),\n",
       " ('objectivePlayerScore', Counter({0.0: 3})),\n",
       " ('participantId', Counter({4.0: 1, 2.0: 2})),\n",
       " ('pentaKills', Counter({0.0: 3})),\n",
       " ('perkPrimaryStyle', Counter({8400.0: 1, 8100.0: 2})),\n",
       " ('perkSubStyle', Counter({8200.0: 1, 8000.0: 2})),\n",
       " ('physicalDamageDealt', Counter({48136.0: 1, 46817.0: 1, 67383.0: 1})),\n",
       " ('physicalDamageDealtToChampions',\n",
       "  Counter({11330.0: 1, 12594.0: 1, 10907.0: 1})),\n",
       " ('physicalDamageTaken', Counter({7246.0: 1, 7109.0: 1, 14573.0: 1})),\n",
       " ('playerScore0', Counter({0.0: 3})),\n",
       " ('playerScore1', Counter({0.0: 3})),\n",
       " ('playerScore2', Counter({0.0: 3})),\n",
       " ('playerScore3', Counter({0.0: 3})),\n",
       " ('playerScore4', Counter({0.0: 3})),\n",
       " ('playerScore5', Counter({0.0: 3})),\n",
       " ('playerScore6', Counter({0.0: 3})),\n",
       " ('playerScore7', Counter({0.0: 3})),\n",
       " ('playerScore8', Counter({0.0: 3})),\n",
       " ('playerScore9', Counter({0.0: 3})),\n",
       " ('quadraKills', Counter({0.0: 3})),\n",
       " ('role', Counter({'SOLO': 1, 'DUO_SUPPORT': 1, 'NONE': 1})),\n",
       " ('sightWardsBoughtInGame', Counter({0.0: 3})),\n",
       " ('timeCCingOthers', Counter({18.0: 1, 59.0: 1, 36.0: 1})),\n",
       " ('totalDamageDealt', Counter({51142.0: 1, 52490.0: 1, 70890.0: 1})),\n",
       " ('totalDamageDealtToChampions',\n",
       "  Counter({13723.0: 1, 13817.0: 1, 11789.0: 1})),\n",
       " ('totalDamageTaken', Counter({8252.0: 1, 11503.0: 1, 16942.0: 1})),\n",
       " ('totalHeal', Counter({1128.0: 1, 3662.0: 1, 8791.0: 1})),\n",
       " ('totalMinionsKilled', Counter({63.0: 1, 58.0: 1, 50.0: 1})),\n",
       " ('totalPlayerScore', Counter({0.0: 3})),\n",
       " ('totalScoreRank', Counter({0.0: 3})),\n",
       " ('totalTimeCrowdControlDealt', Counter({274.0: 1, 123.0: 1, 145.0: 1})),\n",
       " ('totalUnitsHealed', Counter({1.0: 3})),\n",
       " ('tripleKills', Counter({0.0: 3})),\n",
       " ('trueDamageDealt', Counter({0.0: 1, 4704.0: 1, 2277.0: 1})),\n",
       " ('trueDamageDealtToChampions', Counter({0.0: 1, 334.0: 1, 593.0: 1})),\n",
       " ('trueDamageTaken', Counter({0.0: 1, 1019.0: 1, 77.0: 1})),\n",
       " ('turretKills', Counter({2.0: 2, 0.0: 1})),\n",
       " ('unrealKills', Counter({0.0: 3})),\n",
       " ('visionScore', Counter({0.0: 2, 3.0: 1})),\n",
       " ('visionWardsBoughtInGame', Counter({0.0: 3})),\n",
       " ('wardsKilled', Counter({0.0: 3})),\n",
       " ('wardsPlaced', Counter({0.0: 2, 3.0: 1})),\n",
       " ('win', Counter({True: 3})),\n",
       " ('xpDiffPerMinDeltas_0-10',\n",
       "  Counter({371.20000000000016: 1, 84.65999999999998: 1, 0.0: 1})),\n",
       " ('xpDiffPerMinDeltas_10-20', Counter({0.0: 3})),\n",
       " ('xpDiffPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('xpDiffPerMinDeltas_30-end', Counter({0.0: 3})),\n",
       " ('xpPerMinDeltas_0-10', Counter({583.9000000000002: 1, 363.9: 1, 331.8: 1})),\n",
       " ('xpPerMinDeltas_10-20', Counter({0.0: 2, 464.2: 1})),\n",
       " ('xpPerMinDeltas_20-30', Counter({0.0: 3})),\n",
       " ('xpPerMinDeltas_30-end', Counter({0.0: 3}))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(feature, Counter(df[feature].head(n=3))) for feature in list(df)] # which features are categorical?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like just the 'lane' and 'role' features are categorical so let's OHE those. \n",
    "\n",
    "Note also, there are a couple True/False columns. Python and python libraries usually treats them as 1/0 already but we'll explicitly change them just in case it causes trouble later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_lane = pd.get_dummies(df['lane'])\n",
    "dummy_role = pd.get_dummies(df['role'])\n",
    "\n",
    "dummy_role.columns.values[3] = \"NO_ROLE\"\n",
    "dummy_lane.columns.values[3] = \"NO_LANE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>NO_LANE</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BOTTOM  JUNGLE  MIDDLE  NO_LANE  TOP\n",
       "0       0       0       1        0    0\n",
       "1       0       0       0        1    0\n",
       "2       0       1       0        0    0\n",
       "3       0       0       0        0    1\n",
       "4       0       1       0        0    0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_lane.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DUO</th>\n",
       "      <th>DUO_CARRY</th>\n",
       "      <th>DUO_SUPPORT</th>\n",
       "      <th>NO_ROLE</th>\n",
       "      <th>SOLO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DUO  DUO_CARRY  DUO_SUPPORT  NO_ROLE  SOLO\n",
       "0    0          0            0        0     1\n",
       "1    0          0            1        0     0\n",
       "2    0          0            0        1     0\n",
       "3    0          0            1        0     0\n",
       "4    0          0            0        1     0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_role.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['lane', 'role'], axis=1)\n",
    "df = df.join([dummy_role,dummy_lane])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_features = ['firstBloodAssist', 'firstBloodKill', 'firstInhibitorAssist', \n",
    "                    'firstInhibitorKill', 'firstTowerAssist', 'firstTowerKill', 'win']\n",
    "\n",
    "df[boolean_features] = df[boolean_features].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just make sure all our features are numeric now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summoner_id</th>\n",
       "      <th>summoner_name</th>\n",
       "      <th>summoner_level</th>\n",
       "      <th>total_matches</th>\n",
       "      <th>first_match_time</th>\n",
       "      <th>first_match_duration</th>\n",
       "      <th>first_match_id</th>\n",
       "      <th>assists</th>\n",
       "      <th>champLevel</th>\n",
       "      <th>combatPlayerScore</th>\n",
       "      <th>...</th>\n",
       "      <th>DUO</th>\n",
       "      <th>DUO_CARRY</th>\n",
       "      <th>DUO_SUPPORT</th>\n",
       "      <th>NO_ROLE</th>\n",
       "      <th>SOLO</th>\n",
       "      <th>BOTTOM</th>\n",
       "      <th>JUNGLE</th>\n",
       "      <th>MIDDLE</th>\n",
       "      <th>NO_LANE</th>\n",
       "      <th>TOP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>92201075</td>\n",
       "      <td>TrEx18</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-01-16T05:50:54.986000+00:00</td>\n",
       "      <td>0 days 00:14:00.000000000</td>\n",
       "      <td>2695060245</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93650017</td>\n",
       "      <td>iMain N01</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-03-10T06:24:33.477000+00:00</td>\n",
       "      <td>0 days 00:16:41.000000000</td>\n",
       "      <td>2736710108</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92729877</td>\n",
       "      <td>luexolu99</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-03-10T06:56:11.750000+00:00</td>\n",
       "      <td>0 days 00:22:54.000000000</td>\n",
       "      <td>2736716714</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93839689</td>\n",
       "      <td>Md95359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-09T13:05:59.377000+00:00</td>\n",
       "      <td>0 days 00:28:54.000000000</td>\n",
       "      <td>2736217337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93599676</td>\n",
       "      <td>lwvvs</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-03-09T11:42:58.309000+00:00</td>\n",
       "      <td>0 days 00:30:05.000000000</td>\n",
       "      <td>2736195812</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 124 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   summoner_id summoner_name  summoner_level  total_matches  \\\n",
       "0     92201075        TrEx18               5              7   \n",
       "1     93650017     iMain N01               5              6   \n",
       "2     92729877     luexolu99               5              4   \n",
       "3     93839689       Md95359               1              1   \n",
       "4     93599676         lwvvs               5              6   \n",
       "\n",
       "                   first_match_time       first_match_duration  \\\n",
       "0  2018-01-16T05:50:54.986000+00:00  0 days 00:14:00.000000000   \n",
       "1  2018-03-10T06:24:33.477000+00:00  0 days 00:16:41.000000000   \n",
       "2  2018-03-10T06:56:11.750000+00:00  0 days 00:22:54.000000000   \n",
       "3  2018-03-09T13:05:59.377000+00:00  0 days 00:28:54.000000000   \n",
       "4  2018-03-09T11:42:58.309000+00:00  0 days 00:30:05.000000000   \n",
       "\n",
       "   first_match_id  assists  champLevel  combatPlayerScore ...   DUO  \\\n",
       "0      2695060245     16.0        12.0                0.0 ...     0   \n",
       "1      2736710108      4.0        11.0                0.0 ...     0   \n",
       "2      2736716714     10.0        13.0                0.0 ...     0   \n",
       "3      2736217337      0.0         1.0                0.0 ...     0   \n",
       "4      2736195812      7.0        17.0                0.0 ...     0   \n",
       "\n",
       "   DUO_CARRY  DUO_SUPPORT  NO_ROLE  SOLO  BOTTOM  JUNGLE  MIDDLE  NO_LANE  TOP  \n",
       "0          0            0        0     1       0       0       1        0    0  \n",
       "1          0            1        0     0       0       0       0        1    0  \n",
       "2          0            0        1     0       0       1       0        0    0  \n",
       "3          0            1        0     0       0       0       0        0    1  \n",
       "4          0            0        1     0       0       1       0        0    0  \n",
       "\n",
       "[5 rows x 124 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, let's move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Normalize feature values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skipping this step for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Create a prediction task label feature**\n",
    "\n",
    "We are trying to predict, from a player's first match stats, if they will play enough to reach summoner level 3 or greater. \n",
    "\n",
    "Let's see what the summoner level breakdown for players is in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({5: 453, 1: 192, 4: 377, 3: 279, 2: 194})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_counts = Counter(df['summoner_level'])\n",
    "level_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a good amount of each summoner level 1-5. Let's make prediction labels where `level < 3` gets `0` and `level >= 3` gets `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_data = df['summoner_level'].tolist()\n",
    "labels = []\n",
    "\n",
    "for value in level_data:\n",
    "    if value < 3:\n",
    "        labels.append(0)\n",
    "    else:\n",
    "        labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1109, 0: 386})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While there may not be as many players under level 3 as we'd like, there are still over 300 examples in this group, so this may be a reasonable dataset to prototype the viability of our prediction task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Removing unwanted features**\n",
    "\n",
    "Some features like \"summoner_name\" aren't relevant to training our model and others like \"total_matches\" and \"summoner_level\" give the model information we don't want it to have access to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summoner_id',\n",
       " 'summoner_name',\n",
       " 'summoner_level',\n",
       " 'total_matches',\n",
       " 'first_match_time',\n",
       " 'first_match_duration',\n",
       " 'first_match_id',\n",
       " 'assists',\n",
       " 'champLevel',\n",
       " 'combatPlayerScore',\n",
       " 'creepsPerMinDeltas_0-10',\n",
       " 'creepsPerMinDeltas_10-20',\n",
       " 'creepsPerMinDeltas_20-30',\n",
       " 'creepsPerMinDeltas_30-end',\n",
       " 'csDiffPerMinDeltas_0-10',\n",
       " 'csDiffPerMinDeltas_10-20',\n",
       " 'csDiffPerMinDeltas_20-30',\n",
       " 'csDiffPerMinDeltas_30-end',\n",
       " 'damageDealtToObjectives',\n",
       " 'damageDealtToTurrets',\n",
       " 'damageSelfMitigated',\n",
       " 'damageTakenDiffPerMinDeltas_0-10',\n",
       " 'damageTakenDiffPerMinDeltas_10-20',\n",
       " 'damageTakenDiffPerMinDeltas_20-30',\n",
       " 'damageTakenDiffPerMinDeltas_30-end',\n",
       " 'damageTakenPerMinDeltas_0-10',\n",
       " 'damageTakenPerMinDeltas_10-20',\n",
       " 'damageTakenPerMinDeltas_20-30',\n",
       " 'damageTakenPerMinDeltas_30-end',\n",
       " 'deaths',\n",
       " 'doubleKills',\n",
       " 'firstBloodAssist',\n",
       " 'firstBloodKill',\n",
       " 'firstInhibitorAssist',\n",
       " 'firstInhibitorKill',\n",
       " 'firstTowerAssist',\n",
       " 'firstTowerKill',\n",
       " 'goldEarned',\n",
       " 'goldPerMinDeltas_0-10',\n",
       " 'goldPerMinDeltas_10-20',\n",
       " 'goldPerMinDeltas_20-30',\n",
       " 'goldPerMinDeltas_30-end',\n",
       " 'goldSpent',\n",
       " 'id',\n",
       " 'inhibitorKills',\n",
       " 'item0',\n",
       " 'item1',\n",
       " 'item2',\n",
       " 'item3',\n",
       " 'item4',\n",
       " 'item5',\n",
       " 'item6',\n",
       " 'killingSprees',\n",
       " 'kills',\n",
       " 'largestCriticalStrike',\n",
       " 'largestKillingSpree',\n",
       " 'largestMultiKill',\n",
       " 'latest_match_time',\n",
       " 'longestTimeSpentLiving',\n",
       " 'magicDamageDealt',\n",
       " 'magicDamageDealtToChampions',\n",
       " 'magicalDamageTaken',\n",
       " 'neutralMinionsKilled',\n",
       " 'neutralMinionsKilledEnemyJungle',\n",
       " 'neutralMinionsKilledTeamJungle',\n",
       " 'objectivePlayerScore',\n",
       " 'participantId',\n",
       " 'pentaKills',\n",
       " 'perkPrimaryStyle',\n",
       " 'perkSubStyle',\n",
       " 'physicalDamageDealt',\n",
       " 'physicalDamageDealtToChampions',\n",
       " 'physicalDamageTaken',\n",
       " 'playerScore0',\n",
       " 'playerScore1',\n",
       " 'playerScore2',\n",
       " 'playerScore3',\n",
       " 'playerScore4',\n",
       " 'playerScore5',\n",
       " 'playerScore6',\n",
       " 'playerScore7',\n",
       " 'playerScore8',\n",
       " 'playerScore9',\n",
       " 'quadraKills',\n",
       " 'sightWardsBoughtInGame',\n",
       " 'timeCCingOthers',\n",
       " 'totalDamageDealt',\n",
       " 'totalDamageDealtToChampions',\n",
       " 'totalDamageTaken',\n",
       " 'totalHeal',\n",
       " 'totalMinionsKilled',\n",
       " 'totalPlayerScore',\n",
       " 'totalScoreRank',\n",
       " 'totalTimeCrowdControlDealt',\n",
       " 'totalUnitsHealed',\n",
       " 'tripleKills',\n",
       " 'trueDamageDealt',\n",
       " 'trueDamageDealtToChampions',\n",
       " 'trueDamageTaken',\n",
       " 'turretKills',\n",
       " 'unrealKills',\n",
       " 'visionScore',\n",
       " 'visionWardsBoughtInGame',\n",
       " 'wardsKilled',\n",
       " 'wardsPlaced',\n",
       " 'win',\n",
       " 'xpDiffPerMinDeltas_0-10',\n",
       " 'xpDiffPerMinDeltas_10-20',\n",
       " 'xpDiffPerMinDeltas_20-30',\n",
       " 'xpDiffPerMinDeltas_30-end',\n",
       " 'xpPerMinDeltas_0-10',\n",
       " 'xpPerMinDeltas_10-20',\n",
       " 'xpPerMinDeltas_20-30',\n",
       " 'xpPerMinDeltas_30-end',\n",
       " 'DUO',\n",
       " 'DUO_CARRY',\n",
       " 'DUO_SUPPORT',\n",
       " 'NO_ROLE',\n",
       " 'SOLO',\n",
       " 'BOTTOM',\n",
       " 'JUNGLE',\n",
       " 'MIDDLE',\n",
       " 'NO_LANE',\n",
       " 'TOP']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in full dataset: 124\n",
      "Number of features in model training dataset: 115\n"
     ]
    }
   ],
   "source": [
    "extra_features = ['summoner_id', 'summoner_level', 'summoner_name', 'id', 'first_match_time',\n",
    "                  'first_match_id', 'first_match_duration', 'latest_match_time', 'total_matches']\n",
    "\n",
    "num_full_features = df.shape[1]\n",
    "\n",
    "df = df.drop(extra_features, axis=1)\n",
    "\n",
    "num_training_features = df.shape[1]\n",
    "\n",
    "print(\"Number of features in full dataset: {}\".format(num_full_features))\n",
    "print(\"Number of features in model training dataset: {}\".format(num_training_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lastly let's save the ML ready dataset and prediction labels for future use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./data/riot_cleaned_ml_data.csv\", index=False) # dataset\n",
    "pd.DataFrame(labels).to_csv(\"./data/ml_data_labels.csv\", index=False) # labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great! We're finally ready to fit our data to some models!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "<a id='section3'></a>\n",
    "\n",
    "## Step 3) Modeling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ML ready data\n",
    "df = pd.read_csv(\"./data/riot_cleaned_ml_data.csv\", encoding=\"ISO-8859-1\")\n",
    "labels = pd.read_csv(\"./data/ml_data_labels.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Randomize and split data into train/test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our training data and label data\n",
    "X = np.array(df)\n",
    "Y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 1196\n",
      "Training labels: 1196\n",
      "Test examples: 299\n",
      "Test labels: 299\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, train_size=0.80, test_size=0.20, random_state=1)\n",
    "\n",
    "print(\"Training examples: {}\".format(X_train.shape[0]))\n",
    "print(\"Training labels: {}\".format(Y_train.shape[0]))\n",
    "print(\"Test examples: {}\".format(X_test.shape[0]))\n",
    "print(\"Test labels: {}\".format(Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_model = LogisticRegression()\n",
    "log_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression model on test data: 74.25%\n",
      "F1-score for logistic regression model on test data: 0.84\n"
     ]
    }
   ],
   "source": [
    "logistic_accuracy = log_model.score(X_test, Y_test)\n",
    "preds = log_model.predict(X_test)\n",
    "log_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of logistic regression model on test data: {:.2f}%\".format(logistic_accuracy*100))\n",
    "print(\"F1-score for logistic regression model on test data: {:.2f}\".format(log_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Not bad at all!**\n",
    "\n",
    "There are a lot of qualifiers we should point out about this result before we jump for joy, but 74% accuracy on this relatively small dataset with just a vanilla, out of the box, logistic regression model is very encouraging.\n",
    "\n",
    "Next, let's try some other out of the box models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = DecisionTreeClassifier()\n",
    "tree_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 64.21%\n",
      "F1-score for ada boosted model on test data: 0.76\n"
     ]
    }
   ],
   "source": [
    "tree_accuracy = tree_model.score(X_test, Y_test)\n",
    "preds = tree_model.predict(X_test)\n",
    "tree_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(tree_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(tree_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_model = RandomForestClassifier()\n",
    "forest_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 70.90%\n",
      "F1-score for ada boosted model on test data: 0.82\n"
     ]
    }
   ],
   "source": [
    "forest_accuracy = forest_model.score(X_test, Y_test)\n",
    "preds = forest_model.predict(X_test)\n",
    "forest_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(forest_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(forest_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_model = GradientBoostingClassifier()\n",
    "gradient_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 73.91%\n",
      "F1-score for ada boosted model on test data: 0.84\n"
     ]
    }
   ],
   "source": [
    "gradient_accuracy = gradient_model.score(X_test, Y_test)\n",
    "preds = gradient_model.predict(X_test)\n",
    "gradient_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(gradient_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(gradient_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ada Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_model = AdaBoostClassifier()\n",
    "ada_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of ada boosted model on test data: 70.90%\n",
      "F1-score for ada boosted model on test data: 0.81\n"
     ]
    }
   ],
   "source": [
    "ada_accuracy = ada_model.score(X_test, Y_test)\n",
    "preds = ada_model.predict(X_test)\n",
    "ada_f1 = f1_score(Y_test, preds)\n",
    "print(\"Accuracy of ada boosted model on test data: {:.2f}%\".format(ada_accuracy*100))\n",
    "print(\"F1-score for ada boosted model on test data: {:.2f}\".format(ada_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Summary of Basic Models</h3>\n",
    "\n",
    "<br>\n",
    "\n",
    "<table align=\"left\" style=\"width:30%\">\n",
    "    <tr>\n",
    "        <th>Model Type</th>\n",
    "        <th>Accuracy</th>\n",
    "        <th>F1-Score</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Logistic Regression</td>\n",
    "        <td>74.25%</td>\n",
    "        <td>0.84</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Decision Tree</td>\n",
    "        <td>62.21%</td>\n",
    "        <td>0.74</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Random Forest</td>\n",
    "        <td>70.90%</td>\n",
    "        <td>0.82</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Gradient Boosting</td>\n",
    "        <td>73.91%</td>\n",
    "        <td>0.84</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Ada Boosting</td>\n",
    "        <td>70.90%</td>\n",
    "        <td>0.81</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "\n",
    "<p style=\"padding-left:350px;\"> We achieved good results with logistic regression and random forests without any hyperparameter tuning. Because logistic regression worked so well, I'm curious how a small feed-forward neural network will fare on this dataset. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose train/test set to prepare for neural network\n",
    "X_train_network = X_train.T\n",
    "X_test_network = X_test.T\n",
    "Y_train_network = Y_train.reshape(1, Y_train.shape[0])\n",
    "Y_test_network = Y_test.reshape(1, Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (115, 1196)\n",
      "Training labels shape: (1, 1196)\n",
      "\n",
      "\n",
      "Test set shape: (115, 299)\n",
      "Test labels shape: (1, 299)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set shape: {}\".format(X_train_network.shape))\n",
    "print(\"Training labels shape: {}\".format(Y_train_network.shape))\n",
    "print(\"\\n\")\n",
    "print(\"Test set shape: {}\".format(X_test_network.shape))\n",
    "print(\"Test labels shape: {}\".format(Y_test_network.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(X_train_network, Y_train_network, X_test_network, Y_test_network, \n",
    "                   num_layers, nodes_in_layer, num_epochs, learning_rate):\n",
    "\n",
    "    # to allow re-running of the network\n",
    "    ops.reset_default_graph()                         \n",
    "    \n",
    "    # make sure all layers are assigned nodes\n",
    "    assert num_layers == len(nodes_in_layer)\n",
    "\n",
    "    \n",
    "    costs = []\n",
    "    parameters = {}\n",
    "    activations = {}\n",
    "     \n",
    "        \n",
    "    # step 1) placeholders for data\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[X_train_network.shape[0], None], name=\"X_data\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[Y_train_network.shape[0], None], name=\"Y_data\")\n",
    "\n",
    "    \n",
    "    # step 2) initialize network parameters\n",
    "\n",
    "    parameters[\"W1\"] = tf.get_variable(\"W1\", [nodes_in_layer[0],X_train_network.shape[0]], initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "    parameters[\"b1\"] = tf.get_variable(\"b1\", [nodes_in_layer[0],1], initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "    \n",
    "    for i in range(1,num_layers):\n",
    "        parameters[\"W{}\".format(i+1)] = tf.get_variable(\"W{}\".format(i+1), [nodes_in_layer[i],nodes_in_layer[i-1]], \n",
    "                                                        initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "        parameters[\"b{}\".format(i+1)] = tf.get_variable(\"b{}\".format(i+1), [nodes_in_layer[i], 1], \n",
    "                                                        initializer = tf.contrib.layers.xavier_initializer(seed=2))\n",
    "        \n",
    "        \n",
    "    # step 3) forward propagation\n",
    "    \n",
    "    activations[\"Z1\"] = tf.add(tf.matmul(parameters[\"W1\"], X), parameters[\"b1\"])\n",
    "    activations[\"A1\"] = tf.nn.relu(activations[\"Z1\"])\n",
    "    \n",
    "    for i in range(1,num_layers):\n",
    "        activations[\"Z{}\".format(i+1)] = tf.add(tf.matmul(parameters[\"W{}\".format(i+1)],\n",
    "                                                          activations[\"A{}\".format(i)]), parameters[\"b{}\".format(i+1)])\n",
    "        activations[\"A{}\".format(i+1)] = tf.nn.relu(activations[\"Z{}\".format(i)])                      \n",
    "\n",
    "     \n",
    "    # step 4) compute cost\n",
    "    logits = tf.transpose(activations[\"Z{}\".format(num_layers)])\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "    \n",
    "    \n",
    "    # step 5) backpropagation\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    \n",
    "    # step 6) initialize and run Session\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "    \n",
    "            _ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train_network, Y: Y_train_network})\n",
    "                \n",
    "            # Print the cost every epoch\n",
    "            if epoch % 10 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        trained_parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(activations[\"Z{}\".format(num_layers)]), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train_network, Y: Y_train_network}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test_network, Y: Y_test_network}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to use our neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 12 and 25 for 'MatMul_2' (op: 'MatMul') with input shapes: [1,12], [25,?].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[0;32m    687\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 12 and 25 for 'MatMul_2' (op: 'MatMul') with input shapes: [1,12], [25,?].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-31058a3d6888>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# train and test the network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m neural_network(X_train_network, Y_train_network, X_test_network, Y_test_network, \n\u001b[1;32m---> 12\u001b[1;33m                num_layers, nodes_in_layer, num_epochs, learning_rate)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-39-80af2da189e6>\u001b[0m in \u001b[0;36mneural_network\u001b[1;34m(X_train_network, Y_train_network, X_test_network, Y_test_network, num_layers, nodes_in_layer, num_epochs, learning_rate)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         activations[\"Z{}\".format(i+1)] = tf.add(tf.matmul(parameters[\"W{}\".format(i+1)],\n\u001b[1;32m---> 41\u001b[1;33m                                                           activations[\"A{}\".format(i)]), parameters[\"b{}\".format(i+1)])\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Z{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2106\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2107\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2108\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4206\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4207\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4208\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4209\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4210\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3290\u001b[0m           op_def=op_def)\n\u001b[0;32m   3291\u001b[0m       self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[1;32m-> 3292\u001b[1;33m                              compute_device=compute_device)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[1;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[0;32m   3330\u001b[0m     \u001b[1;31m# compute_shapes argument.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3331\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3332\u001b[1;33m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3333\u001b[0m     \u001b[1;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3334\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2494\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2467\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m   \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2470\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m     raise RuntimeError(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m   2397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2398\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2399\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2401\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[1;34m(op, require_shape_fn)\u001b[0m\n\u001b[0;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[0;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m                                   require_shape_fn)\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[1;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 691\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    692\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 12 and 25 for 'MatMul_2' (op: 'MatMul') with input shapes: [1,12], [25,?]."
     ]
    }
   ],
   "source": [
    "# seed for reproducibility\n",
    "tf.set_random_seed(2)\n",
    "\n",
    "# choose your parameters\n",
    "num_layers = 3\n",
    "nodes_in_layer = [25,12,1]\n",
    "num_epochs= 50\n",
    "learning_rate = 0.05\n",
    "\n",
    "# train and test the network\n",
    "neural_network(X_train_network, Y_train_network, X_test_network, Y_test_network, \n",
    "               num_layers, nodes_in_layer, num_epochs, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[n_x, None], name=\"X_data\")\n",
    "    Y = tf.placeholder(tf.float32, shape=[n_y, None], name=\"Y_data\")\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \n",
    "    tf.set_random_seed(1)                   \n",
    "        \n",
    "    W1 = tf.get_variable(\"W1\", [25,115], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [1,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [1,1], initializer = tf.zeros_initializer())\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "\n",
    "    Z1 = tf.add(tf.matmul(W1,X),b1)                        \n",
    "    A1 = tf.nn.relu(Z1)                                   \n",
    "    Z2 = tf.add(tf.matmul(W2,A1),b2)                       \n",
    "    A2 = tf.nn.relu(Z2)                                    \n",
    "    Z3 = tf.add(tf.matmul(W3,A2),b3)                       \n",
    "\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels))\n",
    "\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
    "\n",
    "    np.random.seed(seed)            \n",
    "    m = X.shape[1]                  # number of training examples\n",
    "    mini_batches = []\n",
    "        \n",
    "    # Step 1: Shuffle (X, Y)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation].reshape((1,m))\n",
    "\n",
    "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
    "    num_complete_minibatches = math.floor(m/mini_batch_size) \n",
    "    for k in range(0, num_complete_minibatches):\n",
    "\n",
    "        mini_batch_X = shuffled_X[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "        mini_batch_Y = shuffled_Y[:, k*mini_batch_size:(k+1)*mini_batch_size]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # Handling the end case (last mini-batch < mini_batch_size)\n",
    "    if m % mini_batch_size != 0:\n",
    "\n",
    "        mini_batch_X = shuffled_X[:, (num_complete_minibatches)*mini_batch_size:]\n",
    "        mini_batch_Y = shuffled_Y[:, (num_complete_minibatches)*mini_batch_size:]\n",
    "\n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "\n",
    "    X, Y = create_placeholders(n_x,n_y)\n",
    "\n",
    "\n",
    "    # Initialize parameters\n",
    "    parameters = initialize_parameters()\n",
    "\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = model(X_train_network, Y_train_network, X_test_network, Y_test_network, num_epochs=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in essentially no time, this simple neural network found parameters that fit the training set perfectly AND still performed perfectly on the test set. I'll need to investigate whether this is result is real or if I made a mistake setting up this network..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"#toc\">back to top</a>\n",
    "</div>\n",
    "\n",
    "## End of Part 3\n",
    "\n",
    "## That's it!\n",
    "\n",
    "We've seen that it is possible to predict (with great accuracy) whether a new League of Legends player will ge through their tutorial matches (reach summoner level 3) or not, based only on the gameplay data of that player's first match!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
